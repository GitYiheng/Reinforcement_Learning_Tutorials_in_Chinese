{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度强化学习入门的两篇论文"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在我访问Lincoln Centre for Autonomous Systems时，Maximilian Huettenrauch给我推荐了几篇深度强化学习领域的入门论文，我在这里挑选了两篇："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Arulkumaran, K., Deisenroth, M.P., Brundage, M. and Bharath, A.A., 2017. A Brief Survey of Deep Reinforcement Learning. arXiv preprint arXiv:1708.05866.\n",
    "\n",
    "### 2. Henderson, P., Islam, R., Bachman, P., Pineau, J., Precup, D. and Meger, D., 2017. Deep reinforcement learning that matters. arXiv preprint arXiv:1709.06560."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面就是我自己翻译的\"A Brief Survey of Deep Reinforcement Learning\"的版本，对于有英文阅读能力的同学还是推荐直接阅读原文。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Brief Survey of Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 摘要（Abstract）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "深度强化学习（deep reinforcement learning）有望给人工智能领域带来革命性的改变，并且它也是构建对视觉世界有更高层理解的自动化系统的一个里程碑。如今，深度学习促使强化学习能够应用在以前难以处理的问题上，比如说直接基于像素信息学习玩电子游戏。深度强化学习算法同样也适用于机器人领域，使得机器人的控制策略可以直接从相机输入的现实世界的信息中直接习得。在这篇综述中，我们开头会介绍强化学习的总体概述，然后会涉及到主流的基于价值（value-based）和基于策略（policy-based）的方法。我们的综述会涵盖深度强化学习的核心算法，包涵deep Q-network、trust region policy optimisation还有asynchronous advantage actor-critic。与此同时，我们也强调了深度神经网络的独特优势，专注于基于强化学习的视觉理解。在结尾部分，我们描述了几个在这个领域的研究方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引言（Introduction）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "人工智能（AI，Artificial Intelligence）领域的主要目标之一就是创造完全自主的智能体，这种智能体可以通过在与环境的交互中试错来学习最优的行为策略。制造可以交互并且能有效地进行学习AI系统是一项长期的挑战，这包括了可以感知并且对周围世界做出反应的机器人，还有可以与自然语言和多媒体交互的完全基于软件的智能体。强化学习（RL，Reinforcement Learning）是经历驱动自主学习（experience-driven autonomous learning）的一个基础数学框架。尽管RL在过去取得了一定的成功，过去的方法缺乏可扩展性，本质上受限于维度较低的问题。存在这些限制的原因是强化学习算法和其他算法一样都面临着复杂性问题：内存复杂度、计算复杂度、在机器学习算法应用的问题上相同的复杂度。我们在最近几年见证了深度学习的崛起，深度学习的成功依仗于深度神经网络强大的函数近似（function approximation）和表示学习（representation learning）能力，这也为我们克服这些问题提供了新的工具。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\ldots$未完待续"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初次编辑日期"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018年5月1日"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考文献"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Arulkumaran, K., Deisenroth, M.P., Brundage, M. and Bharath, A.A., 2017. A Brief Survey of Deep Reinforcement Learning. arXiv preprint arXiv:1708.05866.\n",
    "\n",
    "[2] Henderson, P., Islam, R., Bachman, P., Pineau, J., Precup, D. and Meger, D., 2017. Deep reinforcement learning that matters. arXiv preprint arXiv:1709.06560."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
