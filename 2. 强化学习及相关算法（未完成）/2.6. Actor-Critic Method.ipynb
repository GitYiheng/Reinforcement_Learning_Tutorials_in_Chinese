{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actor-critic-based algorithms are among the most popular methods in reinforcement learning. For example, the Deep Deterministic Policy Gradient (DDPG) algorithm is an actor-critic, model-free method. Moreover the actor-critic framework has many links with neuroscience and animal learning, in particular with models of basal ganglia (Takahashi et al., 2008)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor-Critic Methods (and Rats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinforcement learning is deeply connected with **neuroscience**, and often the research in this area pushed the implementation of new algorithms in the computational field. Following this observation I will introduce actor-critic methods with a brief excursion in the neuroscience field. If you have a pure computational background you will learn something new. My objective is to give you a deeper insight into the reinforcement learning (exteded) world. To understand this introduction you should be familiar with the basic structure of the nervous system. What is a neuron? How do neurons communicate using synapses and neurotransmitters? What is cerebral cortex? You do not need to know the details, here I want you to get the general scheme. Let's start from Dopamine. **Dopamine** is a neuromodulator which is implied in some of the most important process in human and animal brains. You can see the dopamine as a messenger which allows neurons to communicate. Dopamine has an important role in different processes in the mammalian brain (e.g. learning, motivation, addiction), and it is produced in two specific areas: **substantia nigra pars compacta** and **ventral tegmental area**. These two areas have direct projections to another area of the brain, the **striatum**. The striatum is divided in two parts: **ventral striatum** and **dorsal striatum**. The output of the striatum is directed to **motor areas** and **prefrontal cortex**, and it is involved in motor control and planning.\n",
    "\n",
    "<img src=\"files/figures/reinforcement_learning_model_free_active_actor_critic_neural_implementation_no_group.png\" style=\"width: 500px;\" />\n",
    "\n",
    "\n",
    "Most of the areas cited before are part of the **basal ganglia**. There are different models that found a connection between basal ganglia and learning. In particular it seems that the phasic activity of the dopaminergic neurons can deliver an error between an old and a new estimate of expected future rewards. The error is very similar to the error in TD learning. Before going into details I would like to simplify the basal ganglia mechanism distinguishing between two groups:\n",
    "\n",
    "1. Ventral striatum, substantia nigra, ventral tegmental area\n",
    "2. Dorsal striatum and motor areas\n",
    "\n",
    "There are no specific biological names for these groups but I will create two labels for the occasion. The first group can evaluate the saliency of a stimulus based on the associated reward. At the same time it can estimate an error measure comparing the result of the action and the direct consequences, and use this value to calibrate an executor. For these reasons I will call it the **critic**. The second group has direct access to actions but no way to estimate the utility of a stimulus, because of that I will call it the **actor**.\n",
    "\n",
    "<img src=\"files/figures/reinforcement_learning_model_free_active_actor_critic_neural_implementation.png\" style=\"width: 500px;\" />\n",
    "\n",
    "The **interaction between actor and critic** has an important role in learning. In particular a consistent research showed that basal ganglia are involved in Pavlovian learning and in procedural (implicit) memory, meaning unconscious memories such as skills and habits. On the other hand the acquisition of declarative (explicit) memory, which is implied in the recollection of factual information, seems to be connected with another area called hippocampus. The only way actor and critic can communicate is through the dopamine released from the substantia nigra after the stimulation of the ventral striatum. **Drug abuse** can have an effect on the **dopaminergic system**, altering the communication between actor and critic. Experiments of Tkahashi et al. (2007) showed that cocaine sensitisation in rats can have as effect maladaptive decision-making. In particular rather than being influenced by long-term goal the rats are driven by immediate rewards. This issue is present in any standard computational frameworks and is known as the **credit assignment problem**. For example, when playing chess it is not easy to isolate the critical actions that lead to the final victory.\n",
    "\n",
    "<img src=\"files/figures/reinforcement_learning_model_free_active_actor_critic_cocaine_rats.png\" style=\"width: 500px;\" />\n",
    "\n",
    "To understand how the neuronal actor-critic mechanism was involved in the credit assignment problem, Takashi et al. (2008) observed the performances of rats pre-sensitised with cocaine in a **Go/No-Go task**. The procedure of a Go/No-Go task is simple. The rat is in a small metallic box and it has to learn to poke a button with the nose when a specific odour (cue) is released. I the rat pokes the button when a positive odour is present it gets a reward (sugar). If the rat pokes the button when a negative odour is present it gets a bitter substance (e.g. quinine). Here positive and negative odours do not mean that they are pleasant or unpleasant, we can consider them as neutral. Learning means to associate a specific odour to a reward and another specific odour to punishment. Finally, if the rat does not move (No-Go) then neither reward nor punishment are given. In total there are four possible conditions.\n",
    "\n",
    "<img src=\"files/figures/reinforcement_learning_model_free_active_actor_critic_go_nogo_rats.png\" style=\"width: 500px;\" />\n",
    "\n",
    "It has been observed that rats pre-sensitised with cocaine do not learn this task, probably because cocaine damages the basal ganglia and the signal returned by the critic became awry. To test this hypothesis Takahashi et al. (2008) sensitised a group of rats 1-3 months before the experiment and then compared it with a non-sensitised control group. The results of the experiment showed that the **rat in the control group** could **learn how to obtain the reward** when the positive odour was presented and how to avoid the punishment with a no-go strategy when the negative odour was presented. The observation of the basal ganglia showed that the ventral striatum (critic) developed some cue-selectivity neurons, which fired when the odour appeared. The observation of the basal ganglia showed that the ventral striatum (critic) developed some cue-selectivity neurons, which fired when the odour appeared. This neurons developed during the training and their activity preceded the responding in the dorsal striatum (actor).\n",
    "\n",
    "<img src=\"files/figures/reinforcement_learning_model_free_active_actor_critic_normal_rats.png\" style=\"width: 500px;\" />\n",
    "\n",
    "On the other hand the **cocaine sensitised rat** did not show any kind of cue-selectivity during the training. Moreover post-mortem analysis showed that those rats did not developed cue-selective neurons in the ventral striatum (critic). These results confirm the hypothesis that the critic learns the value of the cue and it trains the actor regarding the action to execute.\n",
    "\n",
    "<img src=\"files/figures/reinforcement_learning_model_free_active_actor_critic_sensitised_rats.png\" style=\"width: 500px;\" />\n",
    "\n",
    "In this section I showed you now the actor-critic framework is deeply correlated with the **neurobiology of mammalian brain**. This computational model is elegant and it can explain phenomena like Pavlovian learning and drug addiction. However the elegance of the model should not prevent us to criticize it. In fact different experiments did not confirm it. For example, some form of stimulus-reward learning can take place in the absence of dopamine. Moreover dopamine cells can fire before the stimulus, meaning that its value cannot be used for the update. For a good review of neuronal actor-critic models and their limits I suggest you to read the article of Joel et al. (2002)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
