{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器人强化学习的重要性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "论文：\n",
    "\n",
    "Plappert, M., Andrychowicz, M., Ray, A., McGrew, B., Baker, B., Powell, G., Schneider, J., Tobin, J., Chociej, M., Welinder, P. and Kumar, V., 2018. Multi-Goal Reinforcement Learning: Challenging Robotics Environments and Request for Research. arXiv preprint arXiv:1802.09464."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器人强化学习入门的第一篇论文"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般我们在课题的开题报告阶段第一件做的事都是文献综述，从而对要研究的领域有一个大致的了解。而写文献综述一般会先选择阅读这个领域中标题带\"survey\"或是\"review\"的论文，因为这类论文会把研究的问题和主流的方法都进行系统性的介绍，为接下来的论文阅读选择提供思路。因为机器人学有它自己的特点和难点，并不是所有的强化学习算法都适用于机器人领域，所以刚开始阅读的最佳文献应该是关于强化学习在机器人领域的\"survey\"或是\"review\"。而我个人最推荐的一篇就是"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kober, J., Bagnell, J.A. and Peters, J., 2013. Reinforcement learning in robotics: A survey. *The International Journal of Robotics Research*, 32(11), pp.1238-1274."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面就是我自己翻译的版本，对于有英文阅读能力的同学还是推荐直接阅读原文。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 摘要（Abstract）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "强化学习为机器人学提供了设计复杂和难以工程实现的行为的一个框架和一系列工具。换个角度看，机器人研究所面临的问题也为强化学习的发展提供了灵感与冲击还有检验的契机。强化学习和机器人学的关系就好比是数学和物理的关系。在这篇文章中，我们力求通过纵览强化学习在机器人行为生成中的研究来增进这两个研究领域之间的联系。我们同时强调了在机器人强化学习领已获得的成功和所面临的挑战。我们不仅会讨论先前的研究是怎样克服这个复杂的问题的，而且也会讲到在取得这些成功的过程中算法、表示和先验信息（algorithm, representation, and prior knowledge）所扮演的角色。在这些基础上，我们这篇论文的重点也在基于模型（model-based）的方法和无模型（model-free）方法之间的选择，还有基于价值函数（value function-based）的方法和策略搜索（policy search）方法之间的选择。通过细致地分析一个简单的问题，我们不仅展示了怎样有效地应用强化学习方法，而且也指出了有待解决的问题和这方面研究在未来的巨大潜力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引言（Introduction）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有各种各样机器人领域的问题可以很自然地被表述为强化学习中的问题。强化学习（reinforcement learning, or RL）使得机器人可以自主地通过在与环境的交互中试错（trial-and-error）从而探索出一个最优行为策略（an optimal behaviour）。在强化学习中，控制任务的设计者不会明确并详细地给出问题的解决方案，而是只提供一个输出是单一标量的目标函数（a scalar objective function），这个目标函数是用来评估机器人的单步性能（measure the one-step performance）。下图展示了各种各样的用强化学习方法成功完成了指定任务的机器人。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/figures/rl_in_robotics_a_survey_figure_1.png\" style=\"width: 500px;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) OBELIX机器人是一个轮式可移动机器人，它用基于价值函数方法成功学习了推箱子的任务 (Mahadevan and Connell, 1992)\n",
    "\n",
    "(b) Zebra Zero机械臂用无模型策略梯度方法成功学习了插轴入孔的任务 (Gullapalli et al., 1994)\n",
    "\n",
    "(c) Carnegie Mellon的无人机用基于模型的策略搜索方法成功学习了可靠的飞行控制策略 (Bagnell and Schneider, 2001)\n",
    "\n",
    "(d) Sarcos人型机器人（DB）用前向模型成功学习了杆平衡任务 (Schaal, 1996)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们首先来考虑训练机器人实现回乒乓球过网的任务 (Muelling et al., 2012)。在这个任务中，机器人可以观测到球的位置和速度的外部动态变量还有关节位置和速度的内部动态变量。这些变量也许已经充分表述了系统的状态（state） $s$,也就是为预测未来的状态提供了足够的统计信息。机器人可用的动作（action） $a$ 可以是传输给电机的扭矩，也可以是传输给逆向动力学控制系统的目标加速度。用基于球和机械臂的观测值（也就是状态）生成电机指令（也就是动作）的函数 $\\pi$ 被称为策略（policy）。强化学习问题就是寻找能优化长期累积奖励（reward） $R(s,a)$ 的策略的问题。强化学习算法就是被设计来寻找这样的一个（接近）最优策略的。在我们这个回乒乓球过网的任务中，奖励函数可以基于回球成功与否，还有比如能耗这样的辅助标准。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\ldots$未完待续"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初次编辑时间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018年4月29日"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考文献"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Kober, J., Bagnell, J.A. and Peters, J., 2013. Reinforcement learning in robotics: A survey. *The International Journal of Robotics Research*, 32(11), pp.1238-1274.\n",
    "\n",
    "[2] Plappert, M., Andrychowicz, M., Ray, A., McGrew, B., Baker, B., Powell, G., Schneider, J., Tobin, J., Chociej, M., Welinder, P. and Kumar, V., 2018. Multi-Goal Reinforcement Learning: Challenging Robotics Environments and Request for Research. arXiv preprint arXiv:1802.09464."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
